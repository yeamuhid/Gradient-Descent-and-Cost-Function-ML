import numpy as np
import matplotlib.pyplot as plt

# Hypothesis function (for linear regression)
def hypothesis(X, theta):
    return np.dot(X, theta)

# Cost function (mean squared error)
def compute_cost(X, y, theta):
    m = len(y)
    predictions = hypothesis(X, theta)
    cost = (1 / (2 * m)) * np.sum(np.square(predictions - y))
    return cost

# Gradient Descent algorithm
def gradient_descent(X, y, theta, alpha, num_iters):
    m = len(y)
    cost_history = np.zeros(num_iters)
    
    for i in range(num_iters):
        # Calculate the gradient
        gradient = (1 / m) * np.dot(X.T, (hypothesis(X, theta) - y))
        
        # Update the parameters
        theta = theta - alpha * gradient
        
        # Save the cost at each iteration
        cost_history[i] = compute_cost(X, y, theta)
    
    return theta, cost_history

# Example usage
# Data: X (input features), y (target values)
X = np.array([[1, 1], [1, 2], [1, 3], [1, 4]])  # Add a bias term (column of ones)
y = np.array([2, 3, 4, 5])

# Initialize parameters
theta = np.zeros(2)
alpha = 0.1
num_iters = 1000

# Perform gradient descent
theta, cost_history = gradient_descent(X, y, theta, alpha, num_iters)

# Print the final parameters and plot cost history
print(f"Optimized parameters: {theta}")
plt.plot(range(num_iters), cost_history)
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.title('Cost Function over Iterations')
plt.show()
